{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 6: Prepare For Modeling by Pre-Processing Data\n",
    "\n",
    "Your raw data may not be setup to be in the best shape for modeling.\n",
    "\n",
    "Sometimes you need to preprocess your data in order to best present the inherent structure of the problem in your data to the modeling algorithms. \n",
    "In todayâ€™s lesson, you will use the pre-processing capabilities provided by the scikit-learn.\n",
    "\n",
    "The scikit-learn library provides two standard idioms for transforming data. Each transform is useful in different circumstances: \n",
    "* Fit and Multiple Transform and Combined Fit-And-Transform.\n",
    "\n",
    "There are many techniques that you can use to prepare your data for modeling. For example, try out some of the following\n",
    "\n",
    "* Standardize numerical data (e.g. mean of 0 and standard deviation of 1) using the scale and center options.\n",
    "* Normalize numerical data (e.g. to a range of 0-1) using the range option.\n",
    "* Explore more advanced feature engineering such as Binarizing.\n",
    "For example, the snippet below loads the Pima Indians onset of diabetes dataset, calculates the parameters needed to standardize the data, then creates a standardized copy of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/sureshkumar-madala/Datasets/main/pima-indians-diabetes-data.csv\"\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "# summarize transformed data\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
